## 项目相关

## 字节实习

### 项目摘要

​	传统音视频拉流情景下，客户端从CDN拉流，对于部分弱网用户而言，存在时延高，卡顿频繁的问题。基于PCDN的拉流方式，弱网用户可切换到网络通畅的边缘私有节点，实现边缘加速，降低弱网用户的时延和卡顿，优化弱网用户的体验。另一方面，利用打洞方法，将用户的手机节点作为拉流节点，实现一次CDN拉流，多个用户受益的效果，减轻CDN节点压力，实现降本增效。

1. 负责处理传输模块的局部线程死锁问题，利用堆栈分析捕获并进行修改，有效提升了线上Qos指标。
2. 负责高频动态内存分配问题的优化，基于C++模板和operator new，重载new/delete运算符，提供了通用内存池组件，优化了高频内存分配操作，降低了OOM频率。
3. 协助优化客户端节点起播建连过程。实现了边缘节点预连接池，同时和CDN和边缘节点建连，一定程度上加速了客户端拉流节点切换。

### 面试问题

1. 你是用什么工具处理的死锁问题？

   + 死锁问题主要得益于coredump工具和addr2line工具。前者能将出错的程序堆栈信息保存到文件中，后者可以将具体的带有函数符号表的可执行文件和堆栈信息联系起来，将堆栈信息转换为具体函数调用，于是可以清晰明了地捕捉发生死锁的函数位置。

2. 你怎么知道这是死锁引发的问题？这个死锁问题是一个什么样的具体场景？最后怎么解决的？

   + 这是一个偶现的Bug。引发了抖音进程的崩溃，能够引发卡死崩溃，一般是OOM问题，或者线程死锁问题，由于架构设计上涉及很多上下模块的互相调用，优先考虑是死锁问题，然后通过日志分析，对不同线程日志进行grep，发现两线程的日志出现中断，很大程度是死锁问题，最终再通过堆栈分析，确认了就是死锁问题。

   + 死锁涉及到网络通信的上下层模块，它们分属不同开发人员完成，并为对方预留了接口，可是接口在调用后按同步的调用方式牵扯到各自的一个加锁模块A和B，并且两者存在互相调用的关系，两个调用频率存在时间差，是一个偶现的问题。

   + 最终采用了一个巧妙的办法。将其中下层模块里加锁后调用上层接口，也就是加锁后继续调用上层加锁模块，以向上层回馈信息的操作另起一个线程进行处理。这样该线程就总是仅仅索要下层模块这个锁资源，而不再继续索要上层模块的锁资源了。

     ```c++
     class B {
         std::mutex mutexOfBClass;
         void Operation() {
             GetMutex(mutexOfBclass);
         }
     };
     
     class A {
         std::metex mutexOfAClass;
         void Operation() {
             GetMutex(mutexOfAClass);
             // InstanceOfB.Operation();
             ThreadPool.add([&](){ 
                 InstanceOfB.Operation();
             });
         }
     };
     ```

3. 动态内存分配问题怎么优化的？这是一个什么问题场景？

   + 问题场景：在风神平台对私有节点的线上情况进行分析时，发现代理节点存在一些CPU跑超问题。确切来说，就是CPU性能占比偏高的问题，这将对结点代理拉流能力产生严重影响。然后结合火焰图分析，发现new和malloc操作占据了相当的宽度。对于边缘节点端，对于网络通信的数据，是有设置内存池来进行优化的；但在整个代理过程里，对buffer进行分析和日志上报的模块在取得buffer里某些个部分进行分析时，涉及到很多的new操作，这部分模块就是频繁malloc的来源

   ```c++
   template<typename _Ty>
   class MemoryAllocation<_Ty> {
   private:
      	static shared_ptr<MemoryCache> instance;
       void* AllocateMemory(size_t size);
       void RecycleToMemoryCache(void* addr, size_t size);
   public:
       MemoryAllocation() {
           instance = MemoryCache.GetInstance();
       }
       void * operator new(size_t size);
       void operator delete();
   };
   
   class A : MemoryAllocation<A> {};
   
   // new A(...); delete A(...)
   ```

4. 你说你降低了OOM的频率，为什么能降低OOM的频率？

   + 内存池本质就是预先分配的一大块内存，能起到这些作用。
     + **减少内存碎片**：内存池在程序启动时预先申请一大块连续的内存，并按照固定大小切分成较小的内存块。这样，当程序需要分配内存时，直接从内存池中取出一个可用的内存块，避免了频繁的内存分配和释放，减少了内存碎片的产生。
     + **提高内存分配效率**：内存池采用预分配的方式，将内存块事先准备好，不需要像常规内存分配一样向操作系统请求内存。这样一来，内存分配的速度更快，减少了频繁申请内存的开销。
     + **提高内存释放效率**：内存池管理自己的内存块状态，当内存块不再使用时，标记为可用状态，而不是立即释放给操作系统。这样，下次需要分配内存时，直接从可用的内存块中取出，避免了频繁的内存释放操作，提高了内存释放的效率。
     + **灵活控制内存使用**：内存池的大小和分配策略可以根据实际需求进行调整，可以根据系统资源和性能要求，合理设置内存池的大小，避免过度分配内存。

5. OOM问题是怎么引起的？要怎么避免OOM问题？

   + 引发原因
     + **大内存需求**：程序可能需要处理大规模的数据集、图像、视频等大型资源，导致内存需求巨大。如果程序所在的系统资源有限，无法满足这种大内存需求，就会发生OOM。
     + **内存泄漏**：内存泄漏是指程序在**动态分配内存后，没有释放**不再使用的内存，导致内存占用不断增加，最终耗尽可用内存。内存泄漏可能由于**编码错误、循环引用、指针失控**等原因引起。
     + **递归深度过大**：在递归算法中，如果递归深度过大，可能导致栈空间耗尽，从而引发OOM问题。递归调用时要格外注意控制递归深度，或者使用迭代替代递归。
     + **多线程问题**：在多线程程序中，如果线程过多或者线程在短时间内大量分配内存，可能导致内存资源耗尽，出现OOM。此时需要合理控制线程的数量，并采用线程安全的内存管理方式。
     + **不合理的内存管理**：在C++程序中，如果频繁地进行大量小内存的动态分配和释放，可能导致内存碎片增多，最终耗尽可用内存。
   + 如何避免
     + **对大规模数据处理，要合理规划内存需求**：在设计程序时，充分考虑所需的内存量。如果涉及大规模数据处理，尝试使用**流式处理或分块处理**方式，避免一次性加载整个数据集。
     + **使用RAII机制，用智能指针，避免使用裸指针**：C++中可以使用`std::shared_ptr`、`std::unique_ptr`等智能指针来避免手动管理内存，从而减少内存泄漏的可能性。
     + **使用内存池**：实现一个内存池，可以减少内存碎片，并提高内存分配和释放的效率，从而缓解OOM问题。
     + **限制并发线程数**：在多线程程序中，适当限制并发线程数，避免同时运行过多线程，从而减少内存占用和栈空间的消耗。
     + **异常处理**：在内存分配时，及时处理可能发生的异常情况，例如`std::bad_alloc`异常，避免程序崩溃。
     + **定期监控和性能测试**：定期监控程序的内存占用和性能表现，及时发现潜在的OOM问题并进行优化

6. 如果发生了OOM问题，你认为应该怎么处理？

   + **分析日志和堆栈跟踪**：首先，查看程序的日志输出和堆栈跟踪（如果有的话），找出导致OOM的位置和相关信息。确定哪个部分的内存使用量较大，哪些函数在此时被调用。
   + **使用内存分析工具**：使用专业的内存分析工具，例如Valgrind（针对C/C++）、Java VisualVM（针对Java）等，可以帮助检测内存泄漏、查看内存分配和释放情况，帮助定位问题。
   + **使用内存池**：如前所述，实现内存池可以一定程度上减少内存碎片，从而缓解OOM问题。
   + **减少内存使用量**：对于大型数据集或大内存消耗的操作，考虑采用分块处理、流式处理等方法，逐步减少内存使用量。
   + **增加硬件资源**：如果程序的内存需求超出了系统硬件资源的限制，考虑增加硬件资源，如增加物理内存或迁移到更高配置的服务器。
   + **使用RAII机制**：C++中可以使用`std::shared_ptr`、`std::unique_ptr`等智能指针来避免手动管理内存，从而减少内存泄漏的可能性。

7. 弱网用户拉流切换的优化是什么场景？

   + 用户起播，总是先从公网拉CDN的流起播，以确保首次拉流的通畅程度，因为这对用户体验影响很大，如果用户起播就很差，被迅速判断为弱网用户，就需要及时切换到为弱网用户准备的私域节点，从缓存节点里选取一个节点建立连接。线上环境时发现私域代理节点存在响应较慢的问题，通过日志追查，发现存在一部分边缘结点收到请求后，与CDN建立连接时存在超时的问题。假如用户在起播从CDN拉流的同时，也同时私域节点建立连接，就可以缓解这个问题，加速客户端拉流节点的切换。

8. 你说是PCDN，那你了解P2P里面的NAT类型，NAT探测还有内网穿透吗？

   + NAT类型

     + 完全圆锥型
       + 内网socket首次向外发消息时得到一个外网映射，所有外网都能通过这个映射{ip, port}和内网的这个socket主机通信
     + 地址限制型
       + 内网socket首次向外发消息时得到一个外网映射，只有内网的这个socket发给它过消息的外网主机，外网的{ip, XXX}才能发消息到内网的socket上。
     + 端口限制型
       + 内网socket首次向外发消息时得到一个外网映射，只有内网的这个socket发给它过消息的外网主机及指定端口，外网的{ip, port}才能发消息到内网的socket上。
     + 对称型
       + 内网socket和不同的外网主机通信，会有一个不同的{ip, port}映射，只有内网的这个socket发给它过消息的外网主机及指定端口，外网的{ip, port}才能发消息到内网的socket上。

   + NAT探测（0321过程）

     服务器需要两个公网地址ip1, ip2, 需要两个端口port1, port2
     创建4个服务端socket, 分别监听 (ip1, port1) , (ip1, port2), (ip12, port1), (ip2, port2);

     + 客户端使用socket X向(ip1, port1)发送数据
     + 服务端通过(ip2, port2)回复数据, 如果客户端能够收到消息, 则为全锥型, 否则, 继续判断
     + 服务器通过(ip2, port1)回复数据, 如果客户端能够收到消息, 则为IP限制型, 否则, 继续判断
     + 客户端使用socket X向(ip1, port2)发送数据, 如果服务端发现客户端的端口发生变化, 则为对称型, 否则为端口限制型

   + 内网穿透

     + 从上面的NAT类型中可以看出，有4种NAT，一共10种组合

       **1. 完全圆锥型NAT和完全圆锥型NAT**
       这种最简单， 只需要B从辅助服务器拿到A的内外网信息， 就可以和A进行连接
       **2. 完全圆锥型NAT和地址限制型NAT**
       同上
       **3. 完全圆锥型NAT和端口限制性NAT**
       同上
       **4. 完全圆锥型NAT和对称型NAT**
       同上

       **5.地址限制型NAT和地址限制型NAT**

       - 当B从辅助服务器拿到A的内外网信息， B向A发送连接， 这个时候NAT A设备会丢弃掉B发送过来的连接。
       - 这个时候B就向辅助服务器发送请求，让A连接B一次， 连完后B就可以连接到A了，NAT A不再拦截B过来的连接。

       **6.地址限制型NAT和端口限制型NAT**
       同上

       **7.端口限制型NAT和端口限制型NAT**

       同上

       **8.地址限制性NAT和对称型NAT**
       当地址限制型的B向对称型A发送后，对称型可以生成一个ip相同，但端口不同的socket与之通信。
       **9.端口限制型NAT和对称型NAT**
       无法穿透， 因为A需要连过B，B才能连到A，但是A连到B的是一个服务器提供的{ip，port}，是B和服务器通信用的，B再和其他主机通信不会用同一个{ip，port}，这使得B和A无法通信。而B也无法连接到A
       **10.对称型NAT和对称型NAT**
       这种也无法穿透，因为客户机每次请求一个不同的公网地址和端口， NAT会新分配一个端口号，所以从辅助服务器拿到的端口号是无效的（只是针对和服务器相连的端口号）。只能通过不可靠的端口预测法。

### 面试问题

1. 说说基于层次化的状态机和射线检测，碰撞检测有啥用，是什么个东西，什么原理。
   + 层次化状态机就是一个状态机里面嵌入一个子状态机。由子状态机来管理父状态下的细节状态。主要用在人物运动状态控制上。
   + 射线检测的使用主要是对2D手感的一个叫作“土狼时间”的机制进行实现，土狼时间就是指角色离开地面后的一小段时间，让角色依然能够跳跃的机制（实测0.2s左右不会显得突兀）。碰撞体检测就是判断两个2D图形是否相交的一个问题。碰撞体检测主要用于检测水平方向的碰撞，它是每0.02秒检测一次，而土狼时间是垂直方向上的检测，且检测要求更高，采用的是逐帧检测的方式，通过在角色脚底设置一条射线，每帧检测它是否与地面相交，来判断人物是否与地面脱离，当判断到人物的状态为在地上且发现射线不再与地面相交，更新人物的状态，启动计时器，让角色在0.2秒内保持起跳的能力。
2. 什么是MVC模式？
   + MVC模式是设计模式里的一种，Model模型层、View视图层、Control控制层。实际就是进行后台数据和前端呈现的解耦。Model负责持有所有的数据，状态与逻辑。Control则作为一个连接器，连接不同视图，就是一个分层解耦的设计。

## 华为工作

### 面试问题

1. 你为什么才干一个月就想走？
   + 部门规章制度冗杂，无意义的流程又多又麻烦。相比之下，字节的基建做的好了一个层级。
   + 部门定位保守，技术水平不高，没有进攻性。
   + 最重要的还是岗位完全靠抽奖，事先跟HR还有主管说好，结果还是被转去做测试，再呆下去感觉技术水平要废了。

2. 这一个月你有什么收获没有。
   + 一是学习到了华为价值观里有些可取的部分，取其精华去其糟粕，我认为还是有不少值得铭记的地方，像是在岗位上如何恪尽职守，还有一些做事的方法论之类的，比如把事情进行切分，变成更小粒度的事务，会发现能更高效的完成。这样一些值得借鉴的东西。
   + 二是拓宽了人际资源，里面也认识到不少同学，有的也在字节实习过，或是出于对npy的考虑，或是因为华为给的多，最终来到了华为，也同样遇到了进来从前端转成后端的兄弟，一起抱团，互相勉励。

3. 你说说你现在所做的工作？

   + 进部门后被分到了测试的工作，问了主管说组里头缺乏测试人员，也没有专业的测试团队，可能长期要干测试的活，需要做好心理准备。

   + 说回测试的工作，近期主要的工作就是参加Meta ERP项目的功能测试，寻找bug，或者说可以优化用户体验的点，提出更改需求单，和开发人员拉通对齐，优化项目实现。

     + 主要是使用三种方法

       + 等价类划分法：将所有可能输入的数据，划分为若干部分，从每一部分中选取少数有代表性的数据作为测试用例。

       + 边界值分析法：边界值法是对输入或输出边界值进行测试，通常作为等价类划分法的补充。
         + 比如对于一些物料属性的界定，一个描述它的数值输入，它的边界值是否存在溢出的情况，这时候用INT_MAX去测。还有数值范围的界定，比如长度，测试是否忽略了负数，以及如果是使用小数，小数点后是否足够精确等问题。
       
       + 安全性分析：比如在查找的时候输入一个字符串，是否有防止SQL注入攻击等。

## RPC项目

### 项目摘要

1. 基于Reactor模式和线程池实现了服务端下层通信框架。
2. 设计了用于服务器和客户端通信的RPC协议头部。
3. 实现了一套数据序列化和反序列化机制。
4. 基于仿函数工厂实现了同步函数、异步函数服务处理模块。

### 面试问题

1. 请详细解释Reactor模式在您的服务端通信框架中的作用。

   + Reactor模式，是一个事件驱动的异步非阻塞的处理模型。在RPC框架里主要在服务端负责处理和客户端的网络交互。Reactor整体分为主线程和线程池里的子线程，主线程接受来自客户端的连接请求，感知epollevent事件，并把读就绪的socket事件交给线程池里的子线程处理。子线程的主要工作是接收来自主线程的事件，并对其进行处理。比如一个socket读就绪事件，子线程就负责把消息从socket缓冲区里读取出来，并进行反序列化，得到调用服务及其参数的token，利用仿函数工厂生成对应的仿函数服务，并调用该服务，将结果进行序列化，然后写入socket缓冲区，将数据发送到客户端。

2. 在RPC协议头部设计中，您考虑了哪些因素以确保高效的服务器和客户端通信？

   + **1字节版本号：** 考虑在协议头部设计中支持版本控制，以便在未来进行协议升级时保持向后兼容性。
   + **1字节状态位：**只设置了调用成功或失败的标识，其余都是用于拓展的。
   + **2字节服务号：** 服务号作为RPC服务的调用标识，服务端通过这个标识解析出对应的服务。
   + **4字节RPC的ID标识：**标识号作为一个RPC请求的唯一标识，当客户端向服务端发送多个RPC请求并得到来自服务端的反馈时，能根据这个标识将结果返回到指定的请求上。
   + **4字节报文长度：** 在设计协议头部时，考虑头部长度和定界的方式，确保服务器和客户端能够准确解析头部信息。

4. 数据序列化和反序列化在您的项目中扮演了什么角色？您是如何选择和实现这套机制的？

   + 序列化和反序列化主要是维护字节序列和对应的数据结构的关系。实现时，主要考虑三个不同的数据类型。
     + 对于基本数据类型。在枚举类里设置它的标识。序列化时写入枚举标识，再写入对应的值。
     + 对于STL容器类型。在枚举类里设置它的标识。比如vector，序列化时，先写入标识，再序列化元素个数，它是一个uint32_t的类型，再循环序列化它的每一个元素。
     + 对于自定义类型。首先写入枚举类里面的一个CUSTOM标识，再序列化它的成员个数，再序列化各个数据成员。每个需要序列化的类，都继承一个Serializable基类，并实现序列化接口。反序列化时，类型已经在需要调用的服务接口上表示出来了，把各个成员依次反序列化出来然后根据接口形参进行构造即可。这是一种折中的实现，因为C++不支持运行时反射。

4. 在实现同步函数和异步函数服务处理模块时，遇到了哪些问题？怎么解决的？

   + 同步和异步实现上设计了两种方案。第一种存在风险。第二种实现更好。
     + 第一种方案，也是实现的。主要实现是在服务端设置一个仿函数工厂，里面存放一个map映射，映射到一个仿函数基类指针，指向一个具体子类，子类包含了对应服务的函数指针成员，并保存它的形参的指针，然后仿函数工厂就返回这样一个仿函数的基类指针，利用反序列化出来的参数对它进行初始化，然后就能进行调用了。
       + 在RPC头部设置同步异步调用的标识，同步请求到达服务端后，服务端立刻返回结果。异步请求到达服务端后，服务器将结果存储在本地，并建立和对应的调用标识的联系，当客户端请求结果时，就将结果返回给客户，并销毁结果。
       + 存在的问题：对于异步调用，在服务端存储结果可能遭到泛洪攻击的问题。
     + 第二种方案。在客户端实现同步异步调用的逻辑。服务端的处理逻辑不变，在客户端调用RPC服务时，向RPC Tunnel一个回调，当收到来自服务端的结果时，根据Request ID，将结果写入到对应的RPC Request的缓冲区。如果是同步调用，在调用CallService服务的时候，在末尾调用getResult，一直阻塞到它得到RPC的结果。如果是异步调用，则直接返回，在后续调用getResult时，再获取结果。

6. 如何确保您的RPC框架在高并发场景下表现良好？您做了哪些性能优化？

   + 我这个RPC框架场景比较简单，没考虑高并发问题。但我知道一些在现实场景实现负载均衡的办法或者思路。

     + 在客户端或者是反向代理节点，保存有多个服务节点的时候，可以通过随机，轮询，权重计算，最小连接数法或者地址哈希法等办法去实现负载均衡。其中Nginx就提供了地址哈希法。

       https://blog.csdn.net/just_for_that_moment/article/details/122272229

7. 在项目中，您是否考虑了安全性和错误处理？如果有，请谈谈您的实现方法。

   1. **认证和授权：** 在RPC通信中，客户端和服务端之间可能存在安全风险，因此需要考虑对通信进行认证和授权。可以使用安全的身份验证机制，如用户名密码、Token、证书等，确保只有授权的客户端可以访问服务端。
   2. **数据加密：** 对于敏感数据或敏感操作，可以采用数据加密技术来保护数据的安全性，防止数据在传输过程中被窃取或篡改。
   3. **防止代码注入：** 在RPC服务端，要谨慎处理来自客户端的输入数据，避免因为恶意输入导致代码注入和安全漏洞。
   4. **错误处理和异常处理：** 在RPC通信中，出现错误是难免的，要确保系统能够适当地处理错误和异常情况。在客户端，要能够处理服务端返回的错误码和错误信息，以便进行相应的处理。在服务端，要能够捕获并处理各种异常情况，避免因为异常导致系统崩溃。
   5. **超时控制：** 考虑到网络通信可能会存在延迟和阻塞，需要对RPC请求设置合理的超时时间。当RPC请求超时时，要进行适当的处理，例如重试、错误处理或回退策略。
   6. **日志记录：** 在RPC项目中，要做好日志记录，记录重要的操作和异常情况，以便及时发现和解决问题。
   7. **版本控制：** RPC协议可能会随着时间进行更新和演进，要考虑版本控制，确保新旧版本之间的兼容性和平滑升级。
   8. **输入验证和过滤：** 在服务端接收到客户端的请求时，要进行输入验证和过滤，确保输入数据合法和安全，避免因为恶意输入导致安全漏洞。

   在实际项目中，安全性和错误处理都是复杂且关键的问题，不同的项目可能有不同的安全需求和错误处理策略。因此，要根据项目的具体情况，仔细分析和实现相应的安全性措施和错误处理机制，以保障系统的安全和可靠性。

8. 是否有针对不同网络环境的适配策略，比如处理高延迟或不稳定网络连接？

   + **超时设置：** 在RPC通信中，设置合理的超时时间是非常重要的，特别是在面对高延迟的网络环境时。我在客户端和服务端都设置了适当的超时时间，确保在一定时间内能够得到响应，避免长时间阻塞和资源浪费。
   + **重试机制：** 当在高延迟或不稳定网络环境下，RPC请求可能因为网络抖动或丢包等原因导致失败。为了增加请求的可靠性，我在客户端实现了重试机制，当请求失败时会进行重试，直到得到响应或达到最大重试次数。
   + **负载均衡：** 考虑到不同网络环境下的服务器负载情况，我在RPC框架中引入了负载均衡策略，确保客户端能够选择最优的服务器进行通信。这可以帮助在高延迟网络中尽量减少请求发送到拥堵的服务器上。
   + **断线重连：** 针对不稳定网络连接，我在客户端实现了断线重连机制。当与服务端的连接断开后，客户端会尝试重新建立连接，以保持通信的稳定性

9. 请分享您在项目中的一次技术挑战和解决方案，以及从中获得的经验教训。

   + 感觉最难的点就是反序列化的时候对于自定义类型的反序列化。当时想实现C++动态类型反射，就是根据类的名称字符串得到它的类型type。当时想了许多办法，最后都没法实现，归根结底，C++在运行期间，一个对象里保存的关于自身类型的信息是有限的，没有保存对应的可用于反序列化的符号。当时考虑了一些如下方案：
     + 基于动态多态和返回类型协变实现自定义类型反序列化。C++多态里面，对于虚函数返回类型，基类返回基类指针or引用，子类返回子类指针or引用，也算作是重写了基类函数，于是想通过auto自动类型推断来得到一个序列化的结果，但最后发现推断的类型总是为基类。
     + 在tuple里存放不同的类型定义结构体，然后查找得到该类型，并用type_traits萃取得到结构体里定义的typedef，但是无法动态更新，tuple元组是不可变的，新增一个结构体，tuple的类型就发生了改变。

